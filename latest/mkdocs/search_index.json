{
    "docs": [
        {
            "location": "/", 
            "text": "CSV.jl Documentation\n\n\n\n\nCSV.jl Documentation\n\n\nHigh-level interface\n\n\nLower-level utilities\n\n\n\n\n\n\n\n\n\n\nHigh-level interface\n\n\n#\n\n\nCSV.read\n \n \nFunction\n.\n\n\nCSV.read(fullpath::Union{AbstractString,IO}, sink=DataFrame, args...; kwargs...)\n =\n \ntypeof(sink)\n\n\nparses a delimited file into a Julia structure (a DataFrame by default, but any \nData.Sink\n may be given).\n\n\nPositional arguments:\n\n\n\n\nfullpath\n; can be a file name (string) or other \nIO\n instance\n\n\nsink\n; a \nDataFrame\n by default, but may also be other \nData.Sink\n types that support streaming via \nData.Field\n interface\n\n\n\n\nKeyword Arguments:\n\n\n\n\ndelim::Union{Char,UInt8}\n; how fields in the file are delimited\n\n\nquotechar::Union{Char,UInt8}\n; the character that indicates a quoted field that may contain the \ndelim\n or newlines\n\n\nescapechar::Union{Char,UInt8}\n; the character that escapes a \nquotechar\n in a quoted field\n\n\nnull::String\n; an ascii string that indicates how NULL values are represented in the dataset\n\n\nheader\n; column names can be provided manually as a complete Vector{String}, or as an Int/Range which indicates the row/rows that contain the column names\n\n\ndatarow::Int\n; specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s)\n\n\ntypes\n; column types can be provided manually as a complete Vector{DataType}, or in a Dict to reference a column by name or number\n\n\nnullable::Bool\n; indicates whether values can be nullable or not; \ntrue\n by default. If set to \nfalse\n and missing values are encountered, a \nNullException\n will be thrown\n\n\ndateformat::Union{AbstractString,Dates.DateFormat}\n; how all dates/datetimes are represented in the dataset\n\n\nfooterskip::Int\n; indicates the number of rows to skip at the end of the file\n\n\nrows_for_type_detect::Int=100\n; indicates how many rows should be read to infer the types of columns\n\n\nrows::Int\n; indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows\n\n\nuse_mmap::Bool=true\n; whether the underlying file will be mmapped or not while parsing\n\n\n\n\nNote by default, \"string\" or text columns will be parsed as the \nWeakRefString\n type. This is a custom type that only stores a pointer to the actual byte data + the number of bytes. To convert a \nString\n to a standard Julia string type, just call \nstring(::WeakRefString)\n, this also works on an entire column \nstring(::NullableVector{WeakRefString})\n. Oftentimes, however, it can be convenient to work with \nWeakRefStrings\n depending on the ultimate use, such as transfering the data directly to another system and avoiding all the intermediate byte copying.\n\n\nExample usage:\n\n\njulia\n dt = CSV.read(\nbids.csv\n)\n7656334\u00d79 DataFrames.DataFrame\n\u2502 Row     \u2502 bid_id  \u2502 bidder_id                               \u2502 auction \u2502 merchandise      \u2502 device      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502 0       \u2502 \n8dac2b259fd1c6d1120e519fb1ac14fbqvax8\n \u2502 \newmzr\n \u2502 \njewelry\n        \u2502 \nphone0\n    \u2502\n\u2502 2       \u2502 1       \u2502 \n668d393e858e8126275433046bbd35c6tywop\n \u2502 \naeqok\n \u2502 \nfurniture\n      \u2502 \nphone1\n    \u2502\n\u2502 3       \u2502 2       \u2502 \naa5f360084278b35d746fa6af3a7a1a5ra3xe\n \u2502 \nwa00e\n \u2502 \nhome goods\n     \u2502 \nphone2\n    \u2502\n...\n\n\n\n\nsource\n\n\n#\n\n\nCSV.write\n \n \nFunction\n.\n\n\nwrite a \nsource::Data.Source\n out to a \nCSV.Sink\n\n\n\n\nio::Union{String,IO}\n; a filename (String) or \nIO\n type to write the \nsource\n to\n\n\nsource\n; a \nData.Source\n type\n\n\ndelim::Union{Char,UInt8}\n; how fields in the file will be delimited\n\n\nquotechar::Union{Char,UInt8}\n; the character that indicates a quoted field that may contain the \ndelim\n or newlines\n\n\nescapechar::Union{Char,UInt8}\n; the character that escapes a \nquotechar\n in a quoted field\n\n\nnull::String\n; the ascii string that indicates how NULL values will be represented in the dataset\n\n\ndateformat\n; how dates/datetimes will be represented in the dataset\n\n\nquotefields::Bool\n; whether all fields should be quoted or not\n\n\nheader::Bool\n; whether to write out the column names from \nsource\n\n\nappend::Bool\n; start writing data at the end of \nio\n; by default, \nio\n will be reset to its beginning before writing\n\n\n\n\nsource\n\n\n\n\nLower-level utilities\n\n\n#\n\n\nCSV.Source\n \n \nType\n.\n\n\nconstructs a \nCSV.Source\n file ready to start parsing data from\n\n\nimplements the \nData.Source\n interface for providing convenient \nData.stream!\n methods for various \nData.Sink\n types\n\n\nsource\n\n\n#\n\n\nCSV.Sink\n \n \nType\n.\n\n\nconstructs a \nCSV.Sink\n file ready to start writing data to\n\n\nimplements the \nData.Sink\n interface for providing convenient \nData.stream!\n methods for various \nData.Source\n types\n\n\nsource\n\n\n#\n\n\nCSV.Options\n \n \nType\n.\n\n\nRepresents the various configuration settings for csv file parsing.\n\n\nKeyword Arguments:\n\n\n\n\ndelim\n::Union{Char,UInt8} = how fields in the file are delimited\n\n\nquotechar\n::Union{Char,UInt8} = the character that indicates a quoted field that may contain the \ndelim\n or newlines\n\n\nescapechar\n::Union{Char,UInt8} = the character that escapes a \nquotechar\n in a quoted field\n\n\nnull\n::String = indicates how NULL values are represented in the dataset\n\n\ndateformat\n::Union{AbstractString,Dates.DateFormat} = how dates/datetimes are represented in the dataset\n\n\n\n\nsource\n\n\n#\n\n\nCSV.parsefield\n \n \nFunction\n.\n\n\nCSV.parsefield{T}(io::IO, ::Type{T}, opt::CSV.Options=CSV.Options(), row=0, col=0)\n =\n \nNullable{T}\n\n\nio\n is an \nIO\n type that is positioned at the first byte/character of an delimited-file field (i.e. a single cell) leading whitespace is ignored for Integer and Float types. returns a \nNullable{T}\n saying whether the field contains a null value or not (empty field, missing value) field is null if the next delimiter or newline is encountered before any other characters. Specialized methods exist for Integer, Float, String, Date, and DateTime. For other types \nT\n, a generic fallback requires \nparse(T, str::String)\n to be defined. the field value may also be wrapped in \nopt.quotechar\n; two consecutive \nopt.quotechar\n results in a null field \nopt.null\n is also checked if there is a custom value provided (i.e. \"NA\", \"\\N\", etc.) For numeric fields, if field is non-null and non-digit characters are encountered at any point before a delimiter or newline, an error is thrown\n\n\nsource\n\n\n#\n\n\nCSV.readline\n \n \nFunction\n.\n\n\nCSV.readline(io::IO, q='\"', e='\\', buf::IOBuffer=IOBuffer())\n =\n \nString\n \nCSV.readline(source::CSV.Source)\n =\n \nString\n\n\nread a single line from \nio\n (any \nIO\n type) or a \nCSV.Source\n as a string, accounting for potentially embedded newlines in quoted fields (e.g. value1, value2, \"value3 with   embedded newlines\"). Can optionally provide a \nbuf::IOBuffer\n type for buffer reuse\n\n\nsource\n\n\n#\n\n\nCSV.readsplitline\n \n \nFunction\n.\n\n\nCSV.readsplitline(io, d=',', q='\"', e='\\', buf::IOBuffer=IOBuffer())\n =\n \nVector{String}\n \nCSV.readsplitline(source::CSV.Source)\n =\n \nVector{String}\n\n\nread a single line from \nio\n (any \nIO\n type) as a \nVector{String}\n with elements being delimited fields (separated by a delimiter \nd\n). Can optionally provide a \nbuf::IOBuffer\n type for buffer reuse\n\n\nsource\n\n\n#\n\n\nCSV.countlines\n \n \nFunction\n.\n\n\nCSV.countlines(io::IO, quotechar, escapechar)\n =\n \nInt\n \nCSV.countlines(source::CSV.Source)\n =\n \nInt\n\n\ncount the number of lines in a file, accounting for potentially embedded newlines in quoted fields\n\n\nsource", 
            "title": "Home"
        }, 
        {
            "location": "/#csvjl-documentation", 
            "text": "CSV.jl Documentation  High-level interface  Lower-level utilities", 
            "title": "CSV.jl Documentation"
        }, 
        {
            "location": "/#high-level-interface", 
            "text": "#  CSV.read     Function .  CSV.read(fullpath::Union{AbstractString,IO}, sink=DataFrame, args...; kwargs...)  =   typeof(sink)  parses a delimited file into a Julia structure (a DataFrame by default, but any  Data.Sink  may be given).  Positional arguments:   fullpath ; can be a file name (string) or other  IO  instance  sink ; a  DataFrame  by default, but may also be other  Data.Sink  types that support streaming via  Data.Field  interface   Keyword Arguments:   delim::Union{Char,UInt8} ; how fields in the file are delimited  quotechar::Union{Char,UInt8} ; the character that indicates a quoted field that may contain the  delim  or newlines  escapechar::Union{Char,UInt8} ; the character that escapes a  quotechar  in a quoted field  null::String ; an ascii string that indicates how NULL values are represented in the dataset  header ; column names can be provided manually as a complete Vector{String}, or as an Int/Range which indicates the row/rows that contain the column names  datarow::Int ; specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s)  types ; column types can be provided manually as a complete Vector{DataType}, or in a Dict to reference a column by name or number  nullable::Bool ; indicates whether values can be nullable or not;  true  by default. If set to  false  and missing values are encountered, a  NullException  will be thrown  dateformat::Union{AbstractString,Dates.DateFormat} ; how all dates/datetimes are represented in the dataset  footerskip::Int ; indicates the number of rows to skip at the end of the file  rows_for_type_detect::Int=100 ; indicates how many rows should be read to infer the types of columns  rows::Int ; indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows  use_mmap::Bool=true ; whether the underlying file will be mmapped or not while parsing   Note by default, \"string\" or text columns will be parsed as the  WeakRefString  type. This is a custom type that only stores a pointer to the actual byte data + the number of bytes. To convert a  String  to a standard Julia string type, just call  string(::WeakRefString) , this also works on an entire column  string(::NullableVector{WeakRefString}) . Oftentimes, however, it can be convenient to work with  WeakRefStrings  depending on the ultimate use, such as transfering the data directly to another system and avoiding all the intermediate byte copying.  Example usage:  julia  dt = CSV.read( bids.csv )\n7656334\u00d79 DataFrames.DataFrame\n\u2502 Row     \u2502 bid_id  \u2502 bidder_id                               \u2502 auction \u2502 merchandise      \u2502 device      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502 0       \u2502  8dac2b259fd1c6d1120e519fb1ac14fbqvax8  \u2502  ewmzr  \u2502  jewelry         \u2502  phone0     \u2502\n\u2502 2       \u2502 1       \u2502  668d393e858e8126275433046bbd35c6tywop  \u2502  aeqok  \u2502  furniture       \u2502  phone1     \u2502\n\u2502 3       \u2502 2       \u2502  aa5f360084278b35d746fa6af3a7a1a5ra3xe  \u2502  wa00e  \u2502  home goods      \u2502  phone2     \u2502\n...  source  #  CSV.write     Function .  write a  source::Data.Source  out to a  CSV.Sink   io::Union{String,IO} ; a filename (String) or  IO  type to write the  source  to  source ; a  Data.Source  type  delim::Union{Char,UInt8} ; how fields in the file will be delimited  quotechar::Union{Char,UInt8} ; the character that indicates a quoted field that may contain the  delim  or newlines  escapechar::Union{Char,UInt8} ; the character that escapes a  quotechar  in a quoted field  null::String ; the ascii string that indicates how NULL values will be represented in the dataset  dateformat ; how dates/datetimes will be represented in the dataset  quotefields::Bool ; whether all fields should be quoted or not  header::Bool ; whether to write out the column names from  source  append::Bool ; start writing data at the end of  io ; by default,  io  will be reset to its beginning before writing   source", 
            "title": "High-level interface"
        }, 
        {
            "location": "/#lower-level-utilities", 
            "text": "#  CSV.Source     Type .  constructs a  CSV.Source  file ready to start parsing data from  implements the  Data.Source  interface for providing convenient  Data.stream!  methods for various  Data.Sink  types  source  #  CSV.Sink     Type .  constructs a  CSV.Sink  file ready to start writing data to  implements the  Data.Sink  interface for providing convenient  Data.stream!  methods for various  Data.Source  types  source  #  CSV.Options     Type .  Represents the various configuration settings for csv file parsing.  Keyword Arguments:   delim ::Union{Char,UInt8} = how fields in the file are delimited  quotechar ::Union{Char,UInt8} = the character that indicates a quoted field that may contain the  delim  or newlines  escapechar ::Union{Char,UInt8} = the character that escapes a  quotechar  in a quoted field  null ::String = indicates how NULL values are represented in the dataset  dateformat ::Union{AbstractString,Dates.DateFormat} = how dates/datetimes are represented in the dataset   source  #  CSV.parsefield     Function .  CSV.parsefield{T}(io::IO, ::Type{T}, opt::CSV.Options=CSV.Options(), row=0, col=0)  =   Nullable{T}  io  is an  IO  type that is positioned at the first byte/character of an delimited-file field (i.e. a single cell) leading whitespace is ignored for Integer and Float types. returns a  Nullable{T}  saying whether the field contains a null value or not (empty field, missing value) field is null if the next delimiter or newline is encountered before any other characters. Specialized methods exist for Integer, Float, String, Date, and DateTime. For other types  T , a generic fallback requires  parse(T, str::String)  to be defined. the field value may also be wrapped in  opt.quotechar ; two consecutive  opt.quotechar  results in a null field  opt.null  is also checked if there is a custom value provided (i.e. \"NA\", \"\\N\", etc.) For numeric fields, if field is non-null and non-digit characters are encountered at any point before a delimiter or newline, an error is thrown  source  #  CSV.readline     Function .  CSV.readline(io::IO, q='\"', e='\\', buf::IOBuffer=IOBuffer())  =   String   CSV.readline(source::CSV.Source)  =   String  read a single line from  io  (any  IO  type) or a  CSV.Source  as a string, accounting for potentially embedded newlines in quoted fields (e.g. value1, value2, \"value3 with   embedded newlines\"). Can optionally provide a  buf::IOBuffer  type for buffer reuse  source  #  CSV.readsplitline     Function .  CSV.readsplitline(io, d=',', q='\"', e='\\', buf::IOBuffer=IOBuffer())  =   Vector{String}   CSV.readsplitline(source::CSV.Source)  =   Vector{String}  read a single line from  io  (any  IO  type) as a  Vector{String}  with elements being delimited fields (separated by a delimiter  d ). Can optionally provide a  buf::IOBuffer  type for buffer reuse  source  #  CSV.countlines     Function .  CSV.countlines(io::IO, quotechar, escapechar)  =   Int   CSV.countlines(source::CSV.Source)  =   Int  count the number of lines in a file, accounting for potentially embedded newlines in quoted fields  source", 
            "title": "Lower-level utilities"
        }
    ]
}