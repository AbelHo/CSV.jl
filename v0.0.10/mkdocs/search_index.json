{
    "docs": [
        {
            "location": "/", 
            "text": "CSV.jl Documentation\n\n\n\n\nCSV.jl Documentation\n\n\nHigh-level interface\n\n\nLower-level utilities\n\n\n\n\n\n\n\n\n\n\nHigh-level interface\n\n\n#\n\n\nCSV.read\n \n \nFunction\n.\n\n\nCSV.read(fullpath::Union{AbstractString,IO}, sink=DataFrame, args...; kwargs...)\n =\n \ntypeof(sink)\n\n\nparses a delimited file into a Julia structure (a DataFrame by default, but any \nData.Sink\n may be given).\n\n\nPositional arguments:\n\n\n\n\nfullpath\n; can be a file name (string) or other \nIO\n instance\n\n\nsink\n; a \nDataFrame\n by default, but may also be other \nData.Sink\n types that support streaming via \nData.Field\n interface\n\n\n\n\nKeyword Arguments:\n\n\n\n\ndelim::Union{Char,UInt8}\n; how fields in the file are delimited\n\n\nquotechar::Union{Char,UInt8}\n; the character that indicates a quoted field that may contain the \ndelim\n or newlines\n\n\nescapechar::Union{Char,UInt8}\n; the character that escapes a \nquotechar\n in a quoted field\n\n\nnull::String\n; an ascii string that indicates how NULL values are represented in the dataset\n\n\nheader\n; column names can be provided manually as a complete Vector{String}, or as an Int/Range which indicates the row/rows that contain the column names\n\n\ndatarow::Int\n; specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s)\n\n\ntypes\n; column types can be provided manually as a complete Vector{DataType}, or in a Dict to reference a column by name or number\n\n\ndateformat::Union{AbstractString,Dates.DateFormat}\n; how all dates/datetimes are represented in the dataset\n\n\nfooterskip::Int\n; indicates the number of rows to skip at the end of the file\n\n\nrows_for_type_detect::Int=100\n; indicates how many rows should be read to infer the types of columns\n\n\nrows::Int\n; indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows\n\n\nuse_mmap::Bool=true\n; whether the underlying file will be mmapped or not while parsing\n\n\n\n\nNote by default, \"string\" or text columns will be parsed as the \nWeakRefString\n type. This is a custom type that only stores a pointer to the actual byte data + the number of bytes. To convert a \nString\n to a standard Julia string type, just call \nstring(::WeakRefString)\n, this also works on an entire column \nstring(::NullableVector{WeakRefString})\n. Oftentimes, however, it can be convenient to work with \nWeakRefStrings\n depending on the ultimate use, such as transfering the data directly to another system and avoiding all the intermediate byte copying.\n\n\nExample usage:\n\n\njulia\n dt = CSV.read(\nbids.csv\n)\n7656334\u00d79 DataFrames.DataFrame\n\u2502 Row     \u2502 bid_id  \u2502 bidder_id                               \u2502 auction \u2502 merchandise      \u2502 device      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502 0       \u2502 \n8dac2b259fd1c6d1120e519fb1ac14fbqvax8\n \u2502 \newmzr\n \u2502 \njewelry\n        \u2502 \nphone0\n    \u2502\n\u2502 2       \u2502 1       \u2502 \n668d393e858e8126275433046bbd35c6tywop\n \u2502 \naeqok\n \u2502 \nfurniture\n      \u2502 \nphone1\n    \u2502\n\u2502 3       \u2502 2       \u2502 \naa5f360084278b35d746fa6af3a7a1a5ra3xe\n \u2502 \nwa00e\n \u2502 \nhome goods\n     \u2502 \nphone2\n    \u2502\n...\n\n\n\n\nsource\n\n\n#\n\n\nCSV.write\n \n \nFunction\n.\n\n\nwrite a \nsource::Data.Source\n out to a \nCSV.Sink\n\n\n\n\nio::Union{String,IO}\n; a filename (String) or \nIO\n type to write the \nsource\n to\n\n\nsource\n; a \nData.Source\n type\n\n\ndelim::Union{Char,UInt8}\n; how fields in the file will be delimited\n\n\nquotechar::Union{Char,UInt8}\n; the character that indicates a quoted field that may contain the \ndelim\n or newlines\n\n\nescapechar::Union{Char,UInt8}\n; the character that escapes a \nquotechar\n in a quoted field\n\n\nnull::String\n; the ascii string that indicates how NULL values will be represented in the dataset\n\n\ndateformat\n; how dates/datetimes will be represented in the dataset\n\n\nquotefields::Bool\n; whether all fields should be quoted or not\n\n\nheader::Bool\n; whether to write out the column names from \nsource\n\n\nappend::Bool\n; start writing data at the end of \nio\n; by default, \nio\n will be reset to its beginning before writing\n\n\n\n\nsource\n\n\n\n\nLower-level utilities\n\n\nCSV.Source\nCSV.Sink\nCSV.Options\nCSV.parsefield\nCSV.readline(::CSV.Source)\nCSV.readsplitline\nCSV.countlines(::CSV.Source)", 
            "title": "Home"
        }, 
        {
            "location": "/#csvjl-documentation", 
            "text": "CSV.jl Documentation  High-level interface  Lower-level utilities", 
            "title": "CSV.jl Documentation"
        }, 
        {
            "location": "/#high-level-interface", 
            "text": "#  CSV.read     Function .  CSV.read(fullpath::Union{AbstractString,IO}, sink=DataFrame, args...; kwargs...)  =   typeof(sink)  parses a delimited file into a Julia structure (a DataFrame by default, but any  Data.Sink  may be given).  Positional arguments:   fullpath ; can be a file name (string) or other  IO  instance  sink ; a  DataFrame  by default, but may also be other  Data.Sink  types that support streaming via  Data.Field  interface   Keyword Arguments:   delim::Union{Char,UInt8} ; how fields in the file are delimited  quotechar::Union{Char,UInt8} ; the character that indicates a quoted field that may contain the  delim  or newlines  escapechar::Union{Char,UInt8} ; the character that escapes a  quotechar  in a quoted field  null::String ; an ascii string that indicates how NULL values are represented in the dataset  header ; column names can be provided manually as a complete Vector{String}, or as an Int/Range which indicates the row/rows that contain the column names  datarow::Int ; specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s)  types ; column types can be provided manually as a complete Vector{DataType}, or in a Dict to reference a column by name or number  dateformat::Union{AbstractString,Dates.DateFormat} ; how all dates/datetimes are represented in the dataset  footerskip::Int ; indicates the number of rows to skip at the end of the file  rows_for_type_detect::Int=100 ; indicates how many rows should be read to infer the types of columns  rows::Int ; indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows  use_mmap::Bool=true ; whether the underlying file will be mmapped or not while parsing   Note by default, \"string\" or text columns will be parsed as the  WeakRefString  type. This is a custom type that only stores a pointer to the actual byte data + the number of bytes. To convert a  String  to a standard Julia string type, just call  string(::WeakRefString) , this also works on an entire column  string(::NullableVector{WeakRefString}) . Oftentimes, however, it can be convenient to work with  WeakRefStrings  depending on the ultimate use, such as transfering the data directly to another system and avoiding all the intermediate byte copying.  Example usage:  julia  dt = CSV.read( bids.csv )\n7656334\u00d79 DataFrames.DataFrame\n\u2502 Row     \u2502 bid_id  \u2502 bidder_id                               \u2502 auction \u2502 merchandise      \u2502 device      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502 0       \u2502  8dac2b259fd1c6d1120e519fb1ac14fbqvax8  \u2502  ewmzr  \u2502  jewelry         \u2502  phone0     \u2502\n\u2502 2       \u2502 1       \u2502  668d393e858e8126275433046bbd35c6tywop  \u2502  aeqok  \u2502  furniture       \u2502  phone1     \u2502\n\u2502 3       \u2502 2       \u2502  aa5f360084278b35d746fa6af3a7a1a5ra3xe  \u2502  wa00e  \u2502  home goods      \u2502  phone2     \u2502\n...  source  #  CSV.write     Function .  write a  source::Data.Source  out to a  CSV.Sink   io::Union{String,IO} ; a filename (String) or  IO  type to write the  source  to  source ; a  Data.Source  type  delim::Union{Char,UInt8} ; how fields in the file will be delimited  quotechar::Union{Char,UInt8} ; the character that indicates a quoted field that may contain the  delim  or newlines  escapechar::Union{Char,UInt8} ; the character that escapes a  quotechar  in a quoted field  null::String ; the ascii string that indicates how NULL values will be represented in the dataset  dateformat ; how dates/datetimes will be represented in the dataset  quotefields::Bool ; whether all fields should be quoted or not  header::Bool ; whether to write out the column names from  source  append::Bool ; start writing data at the end of  io ; by default,  io  will be reset to its beginning before writing   source", 
            "title": "High-level interface"
        }, 
        {
            "location": "/#lower-level-utilities", 
            "text": "CSV.Source\nCSV.Sink\nCSV.Options\nCSV.parsefield\nCSV.readline(::CSV.Source)\nCSV.readsplitline\nCSV.countlines(::CSV.Source)", 
            "title": "Lower-level utilities"
        }
    ]
}