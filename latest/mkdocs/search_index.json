{
    "docs": [
        {
            "location": "/", 
            "text": "CSV.jl Documentation\n\n\n\n\nCSV.jl Documentation\n\n\nHigh-level interface\n\n\nLower-level utilities\n\n\n\n\n\n\n\n\n\n\nHigh-level interface\n\n\n#\n\n\nCSV.read\n \n \nFunction\n.\n\n\nCSV.read(fullpath::Union{AbstractString,IO}, sink::Type{T}=DataFrame, args...; kwargs...)\n =\n \ntypeof(sink)\n \nCSV.read(fullpath::Union{AbstractString,IO}, sink::Data.Sink; kwargs...)\n =\n \nData.Sink\n\n\nparses a delimited file into a Julia structure (a DataFrame by default, but any \nData.Sink\n may be given).\n\n\nPositional arguments:\n\n\n\n\nfullpath\n; can be a file name (string) or other \nIO\n instance\n\n\nsink::Type{T}\n; \nDataFrame\n by default, but may also be other \nData.Sink\n types that support streaming via \nData.Field\n interface; note that the method argument can be the \ntype\n of \nData.Sink\n, plus any required arguments the sink may need (\nargs...\n).                   or an already constructed \nsink\n may be passed (2nd method above)\n\n\n\n\nKeyword Arguments:\n\n\n\n\ndelim::Union{Char,UInt8}\n; a single character or ascii-compatible byte that indicates how fields in the file are delimited; default is \nUInt8(',')\n\n\nquotechar::Union{Char,UInt8}\n; the character that indicates a quoted field that may contain the \ndelim\n or newlines; default is \nUInt8('\"')\n\n\nescapechar::Union{Char,UInt8}\n; the character that escapes a \nquotechar\n in a quoted field; default is \nUInt8('\\')\n\n\nnull::String\n; an ascii string that indicates how NULL values are represented in the dataset; default is the empty string, \n\"\"\n\n\nheader\n; column names can be provided manually as a complete Vector{String}, or as an Int/Range which indicates the row/rows that contain the column names\n\n\ndatarow::Int\n; specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s); for a file without column names (header), specify \ndatarow=1\n\n\ntypes\n; column types can be provided manually as a complete Vector{DataType}, or in a Dict to reference individual columns by name or number\n\n\nnullable::Bool\n; indicates whether values can be nullable or not; \ntrue\n by default. If set to \nfalse\n and missing values are encountered, a \nNullException\n will be thrown\n\n\ndateformat::Union{AbstractString,Dates.DateFormat}\n; how all dates/datetimes in the dataset are formatted\n\n\nfooterskip::Int\n; indicates the number of rows to skip at the end of the file\n\n\nrows_for_type_detect::Int=100\n; indicates how many rows should be read to infer the types of columns\n\n\nrows::Int\n; indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows; \n-1\n can be passed to skip a full-file scan, but the \nData.Sink\n must be setup account for a potentially unknown # of rows\n\n\nuse_mmap::Bool=true\n; whether the underlying file will be mmapped or not while parsing\n\n\nappend::Bool=false\n; if the \nsink\n argument provided is an existing table, \nappend=true\n will append the source's data to the existing data instead of doing a full replace\n\n\n\n\nNote by default, \"string\" or text columns will be parsed as the \nWeakRefString\n type. This is a custom type that only stores a pointer to the actual byte data + the number of bytes. To convert a \nString\n to a standard Julia string type, just call \nstring(::WeakRefString)\n, this also works on an entire column. Oftentimes, however, it can be convenient to work with \nWeakRefStrings\n depending on the ultimate use, such as transfering the data directly to another system and avoiding all the intermediate copying.\n\n\nExample usage:\n\n\njulia\n dt = CSV.read(\nbids.csv\n)\n7656334\u00d79 DataFrames.DataFrame\n\u2502 Row     \u2502 bid_id  \u2502 bidder_id                               \u2502 auction \u2502 merchandise      \u2502 device      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502 0       \u2502 \n8dac2b259fd1c6d1120e519fb1ac14fbqvax8\n \u2502 \newmzr\n \u2502 \njewelry\n        \u2502 \nphone0\n    \u2502\n\u2502 2       \u2502 1       \u2502 \n668d393e858e8126275433046bbd35c6tywop\n \u2502 \naeqok\n \u2502 \nfurniture\n      \u2502 \nphone1\n    \u2502\n\u2502 3       \u2502 2       \u2502 \naa5f360084278b35d746fa6af3a7a1a5ra3xe\n \u2502 \nwa00e\n \u2502 \nhome goods\n     \u2502 \nphone2\n    \u2502\n...\n\n\n\n\nsource\n\n\n#\n\n\nCSV.write\n \n \nFunction\n.\n\n\nCSV.write(fullpath::Union{AbstractString,IO}, source::Type{T}, args...; kwargs...)\n =\n \nCSV.Sink\n \nCSV.write(fullpath::Union{AbstractString,IO}, source::Data.Source; kwargs...)\n =\n \nCSV.Sink\n\n\nwrite a \nData.Source\n out to a \nCSV.Sink\n.\n\n\nPositional Arguments:\n\n\n\n\nfullpath\n; can be a file name (string) or other \nIO\n instance\n\n\nsource\n can be the \ntype\n of \nData.Source\n, plus any required \nargs...\n, or an already constructed \nData.Source\n can be passsed in directly (2nd method)\n\n\n\n\nKeyword Arguments:\n\n\n\n\ndelim::Union{Char,UInt8}\n; how fields in the file will be delimited; default is \nUInt8(',')\n\n\nquotechar::Union{Char,UInt8}\n; the character that indicates a quoted field that may contain the \ndelim\n or newlines; default is \nUInt8('\"')\n\n\nescapechar::Union{Char,UInt8}\n; the character that escapes a \nquotechar\n in a quoted field; default is \nUInt8('\\')\n\n\nnull::String\n; the ascii string that indicates how NULL values will be represented in the dataset; default is the emtpy string \n\"\"\n\n\ndateformat\n; how dates/datetimes will be represented in the dataset; default is ISO-8601 \nyyyy-mm-ddTHH:MM:SS.s\n\n\nheader::Bool\n; whether to write out the column names from \nsource\n\n\nappend::Bool\n; start writing data at the end of \nio\n; by default, \nio\n will be reset to the beginning before writing\n\n\n\n\nsource\n\n\n\n\nLower-level utilities\n\n\n#\n\n\nCSV.Source\n \n \nType\n.\n\n\nconstructs a \nCSV.Source\n file ready to start parsing data from\n\n\nimplements the \nData.Source\n interface for providing convenient \nData.stream!\n methods for various \nData.Sink\n types\n\n\nsource\n\n\n#\n\n\nCSV.Sink\n \n \nType\n.\n\n\nconstructs a \nCSV.Sink\n file ready to start writing data to\n\n\nimplements the \nData.Sink\n interface for providing convenient \nData.stream!\n methods for various \nData.Source\n types\n\n\nsource\n\n\n#\n\n\nCSV.Options\n \n \nType\n.\n\n\nRepresents the various configuration settings for csv file parsing.\n\n\nKeyword Arguments:\n\n\n\n\ndelim\n::Union{Char,UInt8} = how fields in the file are delimited\n\n\nquotechar\n::Union{Char,UInt8} = the character that indicates a quoted field that may contain the \ndelim\n or newlines\n\n\nescapechar\n::Union{Char,UInt8} = the character that escapes a \nquotechar\n in a quoted field\n\n\nnull\n::String = indicates how NULL values are represented in the dataset\n\n\ndateformat\n::Union{AbstractString,Dates.DateFormat} = how dates/datetimes are represented in the dataset\n\n\n\n\nsource\n\n\n#\n\n\nCSV.parsefield\n \n \nFunction\n.\n\n\nCSV.parsefield{T}(io::IO, ::Type{T}, opt::CSV.Options=CSV.Options(), row=0, col=0)\n =\n \nNullable{T}\n\n\nio\n is an \nIO\n type that is positioned at the first byte/character of an delimited-file field (i.e. a single cell) leading whitespace is ignored for Integer and Float types. returns a \nNullable{T}\n saying whether the field contains a null value or not (empty field, missing value) field is null if the next delimiter or newline is encountered before any other characters. Specialized methods exist for Integer, Float, String, Date, and DateTime. For other types \nT\n, a generic fallback requires \nparse(T, str::String)\n to be defined. the field value may also be wrapped in \nopt.quotechar\n; two consecutive \nopt.quotechar\n results in a null field \nopt.null\n is also checked if there is a custom value provided (i.e. \"NA\", \"\\N\", etc.) For numeric fields, if field is non-null and non-digit characters are encountered at any point before a delimiter or newline, an error is thrown\n\n\nsource\n\n\n#\n\n\nCSV.readline\n \n \nFunction\n.\n\n\nCSV.readline(io::IO, q='\"', e='\\', buf::IOBuffer=IOBuffer())\n =\n \nString\n \nCSV.readline(source::CSV.Source)\n =\n \nString\n\n\nread a single line from \nio\n (any \nIO\n type) or a \nCSV.Source\n as a string, accounting for potentially embedded newlines in quoted fields (e.g. value1, value2, \"value3 with   embedded newlines\"). Can optionally provide a \nbuf::IOBuffer\n type for buffer reuse\n\n\nsource\n\n\n#\n\n\nCSV.readsplitline\n \n \nFunction\n.\n\n\nCSV.readsplitline(io, d=',', q='\"', e='\\', buf::IOBuffer=IOBuffer())\n =\n \nVector{String}\n \nCSV.readsplitline(source::CSV.Source)\n =\n \nVector{String}\n\n\nread a single line from \nio\n (any \nIO\n type) as a \nVector{String}\n with elements being delimited fields (separated by a delimiter \nd\n). Can optionally provide a \nbuf::IOBuffer\n type for buffer reuse\n\n\nsource\n\n\n#\n\n\nCSV.countlines\n \n \nFunction\n.\n\n\nCSV.countlines(io::IO, quotechar, escapechar)\n =\n \nInt\n \nCSV.countlines(source::CSV.Source)\n =\n \nInt\n\n\ncount the number of lines in a file, accounting for potentially embedded newlines in quoted fields\n\n\nsource", 
            "title": "Home"
        }, 
        {
            "location": "/#csvjl-documentation", 
            "text": "CSV.jl Documentation  High-level interface  Lower-level utilities", 
            "title": "CSV.jl Documentation"
        }, 
        {
            "location": "/#high-level-interface", 
            "text": "#  CSV.read     Function .  CSV.read(fullpath::Union{AbstractString,IO}, sink::Type{T}=DataFrame, args...; kwargs...)  =   typeof(sink)   CSV.read(fullpath::Union{AbstractString,IO}, sink::Data.Sink; kwargs...)  =   Data.Sink  parses a delimited file into a Julia structure (a DataFrame by default, but any  Data.Sink  may be given).  Positional arguments:   fullpath ; can be a file name (string) or other  IO  instance  sink::Type{T} ;  DataFrame  by default, but may also be other  Data.Sink  types that support streaming via  Data.Field  interface; note that the method argument can be the  type  of  Data.Sink , plus any required arguments the sink may need ( args... ).                   or an already constructed  sink  may be passed (2nd method above)   Keyword Arguments:   delim::Union{Char,UInt8} ; a single character or ascii-compatible byte that indicates how fields in the file are delimited; default is  UInt8(',')  quotechar::Union{Char,UInt8} ; the character that indicates a quoted field that may contain the  delim  or newlines; default is  UInt8('\"')  escapechar::Union{Char,UInt8} ; the character that escapes a  quotechar  in a quoted field; default is  UInt8('\\')  null::String ; an ascii string that indicates how NULL values are represented in the dataset; default is the empty string,  \"\"  header ; column names can be provided manually as a complete Vector{String}, or as an Int/Range which indicates the row/rows that contain the column names  datarow::Int ; specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s); for a file without column names (header), specify  datarow=1  types ; column types can be provided manually as a complete Vector{DataType}, or in a Dict to reference individual columns by name or number  nullable::Bool ; indicates whether values can be nullable or not;  true  by default. If set to  false  and missing values are encountered, a  NullException  will be thrown  dateformat::Union{AbstractString,Dates.DateFormat} ; how all dates/datetimes in the dataset are formatted  footerskip::Int ; indicates the number of rows to skip at the end of the file  rows_for_type_detect::Int=100 ; indicates how many rows should be read to infer the types of columns  rows::Int ; indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows;  -1  can be passed to skip a full-file scan, but the  Data.Sink  must be setup account for a potentially unknown # of rows  use_mmap::Bool=true ; whether the underlying file will be mmapped or not while parsing  append::Bool=false ; if the  sink  argument provided is an existing table,  append=true  will append the source's data to the existing data instead of doing a full replace   Note by default, \"string\" or text columns will be parsed as the  WeakRefString  type. This is a custom type that only stores a pointer to the actual byte data + the number of bytes. To convert a  String  to a standard Julia string type, just call  string(::WeakRefString) , this also works on an entire column. Oftentimes, however, it can be convenient to work with  WeakRefStrings  depending on the ultimate use, such as transfering the data directly to another system and avoiding all the intermediate copying.  Example usage:  julia  dt = CSV.read( bids.csv )\n7656334\u00d79 DataFrames.DataFrame\n\u2502 Row     \u2502 bid_id  \u2502 bidder_id                               \u2502 auction \u2502 merchandise      \u2502 device      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502 0       \u2502  8dac2b259fd1c6d1120e519fb1ac14fbqvax8  \u2502  ewmzr  \u2502  jewelry         \u2502  phone0     \u2502\n\u2502 2       \u2502 1       \u2502  668d393e858e8126275433046bbd35c6tywop  \u2502  aeqok  \u2502  furniture       \u2502  phone1     \u2502\n\u2502 3       \u2502 2       \u2502  aa5f360084278b35d746fa6af3a7a1a5ra3xe  \u2502  wa00e  \u2502  home goods      \u2502  phone2     \u2502\n...  source  #  CSV.write     Function .  CSV.write(fullpath::Union{AbstractString,IO}, source::Type{T}, args...; kwargs...)  =   CSV.Sink   CSV.write(fullpath::Union{AbstractString,IO}, source::Data.Source; kwargs...)  =   CSV.Sink  write a  Data.Source  out to a  CSV.Sink .  Positional Arguments:   fullpath ; can be a file name (string) or other  IO  instance  source  can be the  type  of  Data.Source , plus any required  args... , or an already constructed  Data.Source  can be passsed in directly (2nd method)   Keyword Arguments:   delim::Union{Char,UInt8} ; how fields in the file will be delimited; default is  UInt8(',')  quotechar::Union{Char,UInt8} ; the character that indicates a quoted field that may contain the  delim  or newlines; default is  UInt8('\"')  escapechar::Union{Char,UInt8} ; the character that escapes a  quotechar  in a quoted field; default is  UInt8('\\')  null::String ; the ascii string that indicates how NULL values will be represented in the dataset; default is the emtpy string  \"\"  dateformat ; how dates/datetimes will be represented in the dataset; default is ISO-8601  yyyy-mm-ddTHH:MM:SS.s  header::Bool ; whether to write out the column names from  source  append::Bool ; start writing data at the end of  io ; by default,  io  will be reset to the beginning before writing   source", 
            "title": "High-level interface"
        }, 
        {
            "location": "/#lower-level-utilities", 
            "text": "#  CSV.Source     Type .  constructs a  CSV.Source  file ready to start parsing data from  implements the  Data.Source  interface for providing convenient  Data.stream!  methods for various  Data.Sink  types  source  #  CSV.Sink     Type .  constructs a  CSV.Sink  file ready to start writing data to  implements the  Data.Sink  interface for providing convenient  Data.stream!  methods for various  Data.Source  types  source  #  CSV.Options     Type .  Represents the various configuration settings for csv file parsing.  Keyword Arguments:   delim ::Union{Char,UInt8} = how fields in the file are delimited  quotechar ::Union{Char,UInt8} = the character that indicates a quoted field that may contain the  delim  or newlines  escapechar ::Union{Char,UInt8} = the character that escapes a  quotechar  in a quoted field  null ::String = indicates how NULL values are represented in the dataset  dateformat ::Union{AbstractString,Dates.DateFormat} = how dates/datetimes are represented in the dataset   source  #  CSV.parsefield     Function .  CSV.parsefield{T}(io::IO, ::Type{T}, opt::CSV.Options=CSV.Options(), row=0, col=0)  =   Nullable{T}  io  is an  IO  type that is positioned at the first byte/character of an delimited-file field (i.e. a single cell) leading whitespace is ignored for Integer and Float types. returns a  Nullable{T}  saying whether the field contains a null value or not (empty field, missing value) field is null if the next delimiter or newline is encountered before any other characters. Specialized methods exist for Integer, Float, String, Date, and DateTime. For other types  T , a generic fallback requires  parse(T, str::String)  to be defined. the field value may also be wrapped in  opt.quotechar ; two consecutive  opt.quotechar  results in a null field  opt.null  is also checked if there is a custom value provided (i.e. \"NA\", \"\\N\", etc.) For numeric fields, if field is non-null and non-digit characters are encountered at any point before a delimiter or newline, an error is thrown  source  #  CSV.readline     Function .  CSV.readline(io::IO, q='\"', e='\\', buf::IOBuffer=IOBuffer())  =   String   CSV.readline(source::CSV.Source)  =   String  read a single line from  io  (any  IO  type) or a  CSV.Source  as a string, accounting for potentially embedded newlines in quoted fields (e.g. value1, value2, \"value3 with   embedded newlines\"). Can optionally provide a  buf::IOBuffer  type for buffer reuse  source  #  CSV.readsplitline     Function .  CSV.readsplitline(io, d=',', q='\"', e='\\', buf::IOBuffer=IOBuffer())  =   Vector{String}   CSV.readsplitline(source::CSV.Source)  =   Vector{String}  read a single line from  io  (any  IO  type) as a  Vector{String}  with elements being delimited fields (separated by a delimiter  d ). Can optionally provide a  buf::IOBuffer  type for buffer reuse  source  #  CSV.countlines     Function .  CSV.countlines(io::IO, quotechar, escapechar)  =   Int   CSV.countlines(source::CSV.Source)  =   Int  count the number of lines in a file, accounting for potentially embedded newlines in quoted fields  source", 
            "title": "Lower-level utilities"
        }
    ]
}